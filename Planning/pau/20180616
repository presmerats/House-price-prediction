ML project
==========

ok-review framework

ok- cross validation lab review

- adapt to framework
	ok- 04_XXXX for models
	ok- 02_XXXX for feature selection/extraction
	ok- 03_XXXX for unsupervised learning
	ok. adapt preprocessing
	- adapt ridge and lasso 
		ok- and add to aux_functions.R
		ok- group scripts, 
		ok- datapreparation
			ko- adapt the outputs to different calls to different files
			ok- review datapreparation_short2
				Inspection
				Missing data
				Outliers
					Histograms
					Mahalanobis (review if its correct)
					Saving data
				Date to montth
				Range vars (from continuous)
				Binary vars
				Ratios
				Logarithms
				Statistical analysis
					Gaussianization
				Feature Selection
					Correlation manual analysis
					Prepared Featuresets -> each one should be a differentt function
					PCA -> not implementated
			ok- create a EDA script from that
				-> remove file daving from 02_datapreparation?
				-> save to 01_EDA.R
				-> should contain PCA also
			ok- create a function with all different selections 
				-allnew
				-orig_no_outliers
				-ratios
				-logs
				-logratios
				-manual_no_correlation_selection
			ok- test everything
			ok- remove 02_datapreparation_short2.R
		- adapt to single file input, single file output
			ok-ridge1
				training test separation
					ok-> split training and test! then va and training
					ok-> split must be random
					ko-> new load function?	
				cv setup
					ridge lambdas? test different lambdas?
					func for se, func for nrmse
				refit after selecting minimal cv
				compute test error and save also
					NRMSE setup
					MSE setup
				write results to txdt file

			ok->fix names of the datasets when saving them as featuresets_files 
				ok-> same name as filenam	(automatically done like that)
				ok-> clean environment? just in case
					
			-> apply to all models! maybe in the main before fitting the models
				ok-model_results.csv change header
				-MODELS
					ok-ridge1 (MASS)
					ok-ridge2
						first k-fold
						then loocv?
->					lasso1  (MASS)
					lasso2
					linear regression
					pcr
					trees

				-for each function
					func header, 
					test & training,  
					cv, 
					refit, 
					train, validation and generalization error
					write
					calls from main
			
		
		- xlsx file also?
		- write comments on Analysis Results/Ridge and Analysis Results/Lasso

	- clean unused R script files
		04_model_fitting_ridge_lasso.R
		
	ok- compute some validation error in order to perform a broad model selection
		ko- we can use the training error after cv? ->no
		- we could do another validation round with the selected models of each type
			ko->must be done over same dataset
			ko->for each data set; for each model; cv model hyper params over cv1; then cv selected model type over cv2; save cv2 error; then refit and compute generalization error
			ko-> maybe cv1 and cv2 can be the same(to have more training individuals)
			->introduce a manual cv computation and save the validation error

- train basic
	 models: lin, poly, ridge, lasso, pcr, trees, 
	 features: pca, ratios,  log, uncorr,
	 make sure: cv then retrain then test

- documentation
	- skeleton
	- basic sections and ideas
	- automatically build tables from results

- train advanced:
	features: 
		PCA features
		clustering with Gower
	models: 
		splines, 
		GAM, 
		PCR, 
		PLS, 
		rvm, 
		neural network, 
		bayesian regression, 
	

- slides
