ML project
==========

ok-review framework

ok- cross validation lab review

- adapt to framework
	ok- 04_XXXX for models
	ok- 02_XXXX for feature selection/extraction
	ok- 03_XXXX for unsupervised learning
	ok. adapt preprocessing
	ok- adapt ridge and lasso 
		ok- and add to aux_functions.R
		ok- group scripts, 
		ok- datapreparation
			ko- adapt the outputs to different calls to different files
			ok- review datapreparation_short2
				Inspection
				Missing data
				Outliers
					Histograms
					Mahalanobis (review if its correct)
					Saving data
				Date to montth
				Range vars (from continuous)
				Binary vars
				Ratios
				Logarithms
				Statistical analysis
					Gaussianization
				Feature Selection
					Correlation manual analysis
					Prepared Featuresets -> each one should be a differentt function
					PCA -> not implementated
			ok- create a EDA script from that
				-> remove file daving from 02_datapreparation?
				-> save to 01_EDA.R
				-> should contain PCA also
			ok- create a function with all different selections 
				-allnew
				-orig_no_outliers
				-ratios
				-logs
				-logratios
				-manual_no_correlation_selection
			ok- test everything
			ok- remove 02_datapreparation_short2.R
		ok- adapt to single file input, single file output
			ok-ridge1
				training test separation
					ok-> split training and test! then va and training
					ok-> split must be random
					ko-> new load function?	
				cv setup
					ridge lambdas? test different lambdas?
					func for se, func for nrmse
				refit after selecting minimal cv
				compute test error and save also
					NRMSE setup
					MSE setup
				write results to txdt file

			ok->fix names of the datasets when saving them as featuresets_files 
				ok-> same name as filenam	(automatically done like that)
				ok-> clean environment? just in case

			ok- compute some validation error in order to perform a broad model selection
				ko- we can use the training error after cv? ->no
				- we could do another validation round with the selected models of each type
					ko->must be done over same dataset
					ko->for each data set; for each model; cv model hyper params over cv1; then cv selected model type over cv2; save cv2 error; then refit and compute generalization error
					ko-> maybe cv1 and cv2 can be the same(to have more training individuals)
					->introduce a manual cv computation and save the validation error
					
			ok-> apply to all models! maybe in the main before fitting the models
				ok-model_results.csv change header
				ok-for each function
					func header, 
					test & training,  
					cv, 
					refit, 
					train, validation and generalization error
					write
					calls from main
			
				-MODELS
					ok-ridge1 (MASS)
					ok-ridge2
					ok-lasso2(glmnet)
					ok-lasso1  (MASS)
					ok-linear regression

		ok- xlsx file also?
		ok- write comments on Analysis Results/Ridge and Analysis Results/Lasso

	ok- clean unused R script files
		04_model_fitting_ridge_lasso.R
		
	ok- PCA prin comp features, and a way to project new values before predict
		PCA (only numerical data, without outliers)
		select prin comps -> numpcs
		PCA( n=numpcs)
		cbind PCA princomp + price
			-> no need to project.. jsut build the dataset


----------------------
				implementation
					ok-pca extraction
					ok-model selection
					ok- write model output to another file? or use another identifier
					ok-feature selection

					ok-feature selection from all datasets in a folder
					ok-implement 3
					ok-implement 4
					ok-implement 1 -> makes no sense
					ok-implement 2 -> it's like full space exploration (done for one model)
					ok-implement 5 -> manually compare results table
					ok-explain each of them

					ok-results table from csv
					ok-fix NRMSE	
						ok-compute also de NRMSE?
						ok-compute also the R^2?
							R^2 = 1 - NRMSE^2
							NRMSE = RMSE/sqrt(Var(t))
						okchange name to RMSE in tables, code etc...
							ok-codes 04
								ok-lasso1
								ok-lasso2
								ok-ridge1
								ok-ridge2
								ok-linear1
								ok-pcr
							ok-table creator code
							ok-csv file
							ok-report
							ok-test
					
					ok-apply results table to each different approach
						GLMNET bug
						final table version
				
					ok-feature selection: forward selection
				
					- linear/lasso/ridge/pcr
						ko- new validation set apart from the training and just use predict over this one
						- perform training and prediction in the cv
							ok-lars lasso 
							ok-glmnet lasso
							ok-glmnet ridge
							ko-mass ridge
							ok-linear
							ok-pcr
							-tree
							-random forest
							
						check lars lasso
						check forward selecction

					eda 
						plots and charts (histograms, logs, ratios,)
						write some explanation

					write everything
					
-------------------------


	- get to know other models
		pcr
		trees
		random forest
		book readings

- continuous vars dataset without outliers -> create dataset

- train basic
	 models: 
	 	lin, 
	 	poly, 
	 	ridge, 
	 	lasso, 
	 	pcr, 
	 	trees,
	 	random forest 
	 features: 
	 	all
	 	continuous only
	 	pca, 
	 	ratios,  
	 	log, 
	 	log+ratios
	 	uncorr subsets,
	experiments:
		for each model
			for each dataset
				get results

	graphs:	plot some comparisons 
		model vs datasets (group by model)
		dataset vs models (group by dataset)
		logic maybe: select best dataset overall, then select best model over it
	conclusions

- documentation
	- skeleton
	- basic sections and ideas
	- automatically build tables from results

- train advanced:
	features: 
		PCA features
		clustering with Gower
	models: 
		splines, 
		GAM,  
		PLS, 
		rvm, 
		neural network, 
		bayesian regression, 
	

- slides
